{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZvud8zCyGC2"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kihe6Uwr7S2K"
      },
      "outputs": [],
      "source": [
        "!pip install medmnist\n",
        "!pip install git+https://github.com/qubvel/classification_models.git\n",
        "!pip install tensorflow==2.16.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3awtntD6tda"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd drive/MyDrive/MLHM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YRngX5wL6pyO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import medmnist\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import layers as layers\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D, Input, ReLU\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from classification_models.keras import Classifiers\n",
        "from shvit import SHVIT\n",
        "from utils import load_data, cal_metrics, train, evaluate\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEUzMZzP6pyP"
      },
      "source": [
        "# Load and View Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msFTLWTT6pyR"
      },
      "outputs": [],
      "source": [
        "data_flag = 'chestmnist'\n",
        "dataset_folder = f'./{data_flag}'\n",
        "model_folder = './saved_models'\n",
        "download = False\n",
        "info = medmnist.INFO[data_flag]\n",
        "task, n_samples, n_channels, n_classes, label_dict = info['task'], info['n_samples'], info['n_channels'], len(info['label']), info['label']\n",
        "\n",
        "print('Task:', task)\n",
        "print('Number of samples:', n_samples)\n",
        "print('Number of channels:', n_channels)\n",
        "print('Number of classes:', n_classes)\n",
        "print('Label Dict:', label_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HtTHPbHP6pyS"
      },
      "outputs": [],
      "source": [
        "# if not os.path.exists(dataset_folder):\n",
        "#     download = True\n",
        "#     os.makedirs(dataset_folder)\n",
        "\n",
        "# size_flags = [64, 128, 224]\n",
        "# for size_flag in size_flags:\n",
        "#     train_dataset = DataClass(root=dataset_folder, size=size_flag, split='train', download=download)\n",
        "#     valid_dataset = DataClass(root=dataset_folder, size=size_flag, split='val', download=download)\n",
        "#     test_dataset = DataClass(root=dataset_folder, size=size_flag, split='test', download=download)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rHgo3CTTiLH4"
      },
      "outputs": [],
      "source": [
        "# data_224 = load_data(dataset_folder, data_flag, size_flag=224)\n",
        "# train_images_224, train_labels_224, val_images_224, val_labels_224, test_images_224, test_labels_224 = data_224[0], data_224[1], data_224[2], data_224[3], data_224[4], data_224[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKW1p7RsLLio"
      },
      "outputs": [],
      "source": [
        "# df_rows = []\n",
        "\n",
        "# def stats(sett):\n",
        "#   for c, disease in label_dict.items():\n",
        "#       count = np.sum(eval(f'{sett}_labels_224')[:, int(c)]==1)\n",
        "#       df_rows.append([sett, disease, count])\n",
        "\n",
        "# stats('train')\n",
        "# stats('val')\n",
        "# stats('test')\n",
        "# dataset_df = pd.DataFrame(df_rows, columns=['set', 'disease', 'count'])\n",
        "\n",
        "# for d in label_dict.values():\n",
        "#   ids = dataset_df['disease']==d\n",
        "#   df_rows.append(['whole', d, np.sum(dataset_df[ids]['count'])])\n",
        "\n",
        "# dataset_df = pd.DataFrame(df_rows, columns=['set', 'disease', 'count'])\n",
        "# dataset_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGav--TwSXJD"
      },
      "outputs": [],
      "source": [
        "# def plot_pie(sett):\n",
        "#     df = dataset_df[dataset_df['set']==sett]\n",
        "#     plt.figure(figsize=(7, 7))\n",
        "#     plt.pie(x=df['count'], labels=df['disease'], autopct=lambda pct: '{:1.1f}%'.format(pct) if pct > 5 else '',\n",
        "#             pctdistance=0.7, labeldistance=1.1, textprops={'size': 'xx-large'})\n",
        "\n",
        "#     plt.savefig(f'{sett}.pdf', bbox_inches='tight')\n",
        "#     plt.show()\n",
        "\n",
        "# plot_pie('whole')\n",
        "# plot_pie('train')\n",
        "# plot_pie('val')\n",
        "# plot_pie('test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_JqK8WC6pyf"
      },
      "outputs": [],
      "source": [
        "# label_texts = info['label']\n",
        "# nr, nc = 2, 7\n",
        "# fig, axes = plt.subplots(nrows=nr, ncols=nc, sharex=True, sharey=True, figsize=(20, 7))\n",
        "# axes = axes.reshape(nr*nc)\n",
        "\n",
        "# for ax, class_id in zip(axes, range(0, 14)):\n",
        "#     title = ''\n",
        "#     # get images that have current class_id\n",
        "#     image_ids = np.where(train_labels_224[:, class_id]==1)[0]\n",
        "#     images = train_images_224[image_ids]\n",
        "#     labels = train_labels_224[image_ids]\n",
        "\n",
        "#     # get image that has most diseases\n",
        "#     sum_by_row = np.sum(images, axis=1)\n",
        "#     image_id = np.where(sum_by_row == np.max(sum_by_row))[0][0]\n",
        "#     label_ids = np.where(labels[image_id] == 1)[0]\n",
        "#     for i in label_ids:\n",
        "#         title += label_texts[str(i)] + '\\n'\n",
        "#     title = title[:-1]\n",
        "\n",
        "#     ax.imshow(train_images_224[image_id], cmap='gray')\n",
        "#     ax.axis('off')\n",
        "#     ax.set_title(title)\n",
        "\n",
        "# plt.savefig('dataset.pdf', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# label_texts = info['label']\n",
        "\n",
        "# for class_id in range(0, 14):\n",
        "#     # get images that have current class_id\n",
        "#     image_ids = np.where(train_labels_224[:, class_id]==1)[0]\n",
        "#     images = train_images_224[image_ids]\n",
        "#     labels = train_labels_224[image_ids]\n",
        "\n",
        "#     # get image that has most diseases\n",
        "#     sum_by_row = np.sum(images, axis=1)\n",
        "#     image_id = np.where(sum_by_row == np.max(sum_by_row))[0][0]\n",
        "#     label_ids = np.where(labels[image_id] == 1)[0]\n",
        "\n",
        "#     im = Image.fromarray(train_images_224[image_id])\n",
        "#     im.save(f'./images_64/raw_example_{image_id}_{str(label_ids)}.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHc7nTOtMQlK"
      },
      "outputs": [],
      "source": [
        "# plt.imshow(train_images_224[0], cmap='gray')\n",
        "# plt.axis('off')\n",
        "# plt.savefig('raw_example.jpg', bbox_inches='tight')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FufcuKvLoDHr"
      },
      "source": [
        "# Models and Training Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKhpvE9iIZZm"
      },
      "outputs": [],
      "source": [
        "def CNN(image_size, n_classes):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', input_shape=(image_size, image_size, 1)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(n_classes, activation='sigmoid'))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvV3tKgFnyIv"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(model_folder):\n",
        "    os.makedirs(model_folder)\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "N_EPOCHS = 30\n",
        "LR = 0.001\n",
        "WEIGHT_DECAY = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "IC0ONxoHd1KR"
      },
      "outputs": [],
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomTranslation(0.1, 0.1),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomFlip('horizontal_and_vertical')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NF2K6zlknKL"
      },
      "source": [
        "# 64x64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LqWIsv21pK1b"
      },
      "outputs": [],
      "source": [
        "image_size_64 = 64\n",
        "data_64 = load_data(dataset_folder, data_flag, size_flag=image_size_64)\n",
        "X_train_64, Y_train_64, X_valid_64, Y_valid_64, X_test_64, Y_test_64 = data_64[0], data_64[1], data_64[2], data_64[3], data_64[4], data_64[5]\n",
        "X_train_64, X_valid_64, X_test_64 = np.expand_dims(X_train_64, axis=-1)/255, np.expand_dims(X_valid_64, axis=-1)/255, np.expand_dims(X_test_64, axis=-1)/255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9j26NuoJ-5Q"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5Jv8XUfKAOc"
      },
      "outputs": [],
      "source": [
        "cnn_64_path = f'{model_folder}/cnn_64.weights.h5'\n",
        "cnn_64 = CNN(image_size_64, n_classes)\n",
        "cnn_64.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HddJa1AZIRtF"
      },
      "outputs": [],
      "source": [
        "cnn_64.compile(optimizer=Adam(learning_rate=LR, weight_decay=WEIGHT_DECAY), loss='binary_crossentropy')\n",
        "train(cnn_64, X_train_64, Y_train_64, n_epochs=N_EPOCHS, batch_size=BATCH_SIZE, model_path=cnn_64_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CairrhTEMdKd"
      },
      "outputs": [],
      "source": [
        "cnn_64.load_weights(cnn_64_path)\n",
        "test_metrics = evaluate(cnn_64, X_test_64, Y_test_64)\n",
        "print(f'test_acc: {test_metrics[0]}; test_f1: {test_metrics[1]}; test_auc: {test_metrics[2]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuSXGlTo0Y4L"
      },
      "source": [
        "## VGG-16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gj6toho905xC"
      },
      "outputs": [],
      "source": [
        "VGG16, preprocess_input = Classifiers.get('vgg16')\n",
        "vgg16_64 = VGG16(input_shape=(image_size_64, image_size_64, 3), weights='imagenet', include_top=False)\n",
        "# for layer in vgg16_64.layers:\n",
        "#     layer.trainable = False\n",
        "new_input = Input(shape=(image_size_64, image_size_64, 1))\n",
        "x = Conv2D(filters=3, kernel_size=(3, 3), padding=\"same\", activation=None)(new_input)\n",
        "x = vgg16_64(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "prediction = Dense(n_classes, activation='sigmoid')(x)\n",
        "vgg16_64 = Model(inputs=new_input, outputs=prediction)\n",
        "vgg16_64.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOFlAgZ53IxN"
      },
      "outputs": [],
      "source": [
        "vgg16_64_path = f'{model_folder}/vgg16_64.weights.h5'\n",
        "vgg16_64.compile(optimizer=Adam(learning_rate=LR, weight_decay=WEIGHT_DECAY), loss='binary_crossentropy')\n",
        "train(vgg16_64, X_train_64, Y_train_64, n_epochs=N_EPOCHS, batch_size=BATCH_SIZE, model_path=vgg16_64_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pP9wuKyceAb1"
      },
      "outputs": [],
      "source": [
        "vgg16_64.load_weights(vgg16_64_path)\n",
        "test_metrics = evaluate(vgg16_64, X_test_64, Y_test_64)\n",
        "print(f'test_acc: {test_metrics[0]}; test_f1: {test_metrics[1]}; test_auc: {test_metrics[2]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-zhBIXTEIuV"
      },
      "source": [
        "## VGG-19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiklumrTEJuF"
      },
      "outputs": [],
      "source": [
        "VGG19, preprocess_input = Classifiers.get('vgg19')\n",
        "vgg19_64 = VGG19(input_shape=(image_size_64, image_size_64, 3), weights='imagenet', include_top=False)\n",
        "# for layer in vgg19_64.layers:\n",
        "#     layer.trainable = False\n",
        "new_input = Input(shape=(image_size_64, image_size_64, 1))\n",
        "x = Conv2D(filters=3, kernel_size=(3, 3), padding=\"same\", activation=None)(new_input)\n",
        "x = vgg19_64(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "prediction = Dense(n_classes, activation='sigmoid')(x)\n",
        "vgg19_64 = Model(inputs=new_input, outputs=prediction)\n",
        "vgg19_64.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3zR26fyEbsI"
      },
      "outputs": [],
      "source": [
        "vgg19_64_path = f'{model_folder}/vgg19_64.weights.h5'\n",
        "vgg19_64.compile(optimizer=Adam(learning_rate=LR, weight_decay=WEIGHT_DECAY), loss=B'binary_crossentropy')\n",
        "train(vgg19_64, X_train_64, Y_train_64, n_epochs=N_EPOCHS, model_path=vgg19_64_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABuT3tp3nzng"
      },
      "outputs": [],
      "source": [
        "vgg19_64.load_weights(vgg19_64_path)\n",
        "test_metrics = evaluate(vgg19_64, X_test_64, Y_test_64)\n",
        "print(f'test_acc: {test_metrics[0]}; test_f1: {test_metrics[1]}; test_auc: {test_metrics[2]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHr8yhf9Jzp-"
      },
      "source": [
        "## ResNet-18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YI-8R7tsKGQH"
      },
      "outputs": [],
      "source": [
        "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
        "resnet18_64 = ResNet18(input_shape=(image_size_64, image_size_64, 3), weights='imagenet', include_top=False)\n",
        "# for layer in resnet18_64.layers:\n",
        "#     layer.trainable = False\n",
        "new_input = Input(shape=(image_size_64, image_size_64, 1))\n",
        "x = Conv2D(filters=3, kernel_size=(3, 3), padding=\"same\", activation='relu')(new_input)\n",
        "x = resnet18_64(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "prediction = Dense(n_classes, activation='sigmoid')(x)\n",
        "resnet18_64 = Model(inputs=new_input, outputs=prediction)\n",
        "resnet18_64.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fz7QioGfKKvq"
      },
      "outputs": [],
      "source": [
        "resnet18_64_path = f'{model_folder}/resnet18_64.weights.h5'\n",
        "resnet18_64.compile(optimizer=Adam(learning_rate=LR, weight_decay=WEIGHT_DECAY), loss='binary_crossentropy')\n",
        "train(resnet18_64, X_train_64, Y_train_64, n_epochs=N_EPOCHS, batch_size=BATCH_SIZE, model_path=resnet18_64_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwUXeA9iLeu8"
      },
      "outputs": [],
      "source": [
        "resnet18_64.load_weights(resnet18_64_path)\n",
        "test_metrics = evaluate(resnet18_64, X_test_64, Y_test_64)\n",
        "print(f'test_acc: {test_metrics[0]}; test_f1: {test_metrics[1]}; test_auc: {test_metrics[2]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iPfmfm8NA1T"
      },
      "source": [
        "## ResNet-50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfPpPiIPNGtX"
      },
      "outputs": [],
      "source": [
        "ResNet50, preprocess_input = Classifiers.get('resnet50')\n",
        "resnet50_64 = ResNet50(input_shape=(image_size_64, image_size_64, 3), weights='imagenet', include_top=False)\n",
        "# for layer in resnet50_64.layers:\n",
        "#     layer.trainable = False\n",
        "new_input = Input(shape=(image_size_64, image_size_64, 1))\n",
        "x = Conv2D(filters=3, kernel_size=(3, 3), padding=\"same\", activation='relu')(new_input)\n",
        "x = resnet50_64(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "prediction = Dense(n_classes, activation='sigmoid')(x)\n",
        "resnet50_64 = Model(inputs=new_input, outputs=prediction)\n",
        "resnet50_64.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlET_rodNJ-j"
      },
      "outputs": [],
      "source": [
        "resnet50_64_path = f'{model_folder}/resnet50_64.weights.h5'\n",
        "resnet50_64.compile(optimizer=Adam(learning_rate=LR, weight_decay=WEIGHT_DECAY), loss='binary_crossentropy')\n",
        "train(resnet50_64, X_train_64, Y_train_64, n_epochs=N_EPOCHS, batch_size=BATCH_SIZE, model_path=resnet50_64_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMYAdjW-moVR"
      },
      "outputs": [],
      "source": [
        "resnet50_64.load_weights(resnet50_64_path)\n",
        "test_metrics = evaluate(resnet50_64, X_test_64, Y_test_64)\n",
        "print(f'test_acc: {test_metrics[0]}; test_f1: {test_metrics[1]}; test_auc: {test_metrics[2]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GdoRXPkW9Js"
      },
      "source": [
        "## SHViT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJwvFNMWnNNq"
      },
      "outputs": [],
      "source": [
        "shvit_settings = {\n",
        "        'embed_dim': [128, 224, 320],\n",
        "        'depth': [2, 4, 5],\n",
        "        'partial_dim': [32, 48, 68],\n",
        "        'types' : ['i', 's', 's']\n",
        "    }\n",
        "shvit = SHVIT(**shvit_settings)\n",
        "input = Input(shape=(image_size_64, image_size_64, 1))\n",
        "output = shvit(input)\n",
        "shvit_64 = Model(inputs=input, outputs=output)\n",
        "shvit_64.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IefW2tyTZAqr"
      },
      "outputs": [],
      "source": [
        "shvit_64_path = f'{model_folder}/shvit_64.weights.h5'\n",
        "shvit_64.compile(optimizer=Adam(learning_rate=LR, weight_decay=WEIGHT_DECAY), loss='binary_crossentropy')\n",
        "train(shvit_64, X_train_64, Y_train_64, n_epochs=N_EPOCHS, batch_size=BATCH_SIZE, model_path=shvit_64_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39XRUT24xxr3"
      },
      "outputs": [],
      "source": [
        "shvit_64.load_weights(shvit_64_path)\n",
        "test_metrics = evaluate(shvit_64, X_test_64, Y_test_64)\n",
        "print(f'test_acc: {test_metrics[0]}; test_f1: {test_metrics[1]}; test_auc: {test_metrics[2]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sP9L7sovdX9y"
      },
      "source": [
        "# 128x128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5LkFSuNdZi1"
      },
      "outputs": [],
      "source": [
        "image_size_128 = 128\n",
        "data_128 = load_data(dataset_folder, data_flag, size_flag=image_size_128)\n",
        "X_train_128, Y_train_128, X_valid_128, Y_valid_128, X_test_128, Y_test_128 = data_128[0], data_128[1], data_128[2], data_128[3], data_128[4], data_128[5]\n",
        "X_train_128, X_valid_128, X_test_128 = np.expand_dims(X_train_128, axis=-1)/255, np.expand_dims(X_valid_128, axis=-1)/255, np.expand_dims(X_test_128, axis=-1)/255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eVoruS7d8cO"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMF8UcZwd786"
      },
      "outputs": [],
      "source": [
        "cnn_128 = CNN(image_size_128, n_classes)\n",
        "cnn_128.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viNQ-lb1eWqN"
      },
      "outputs": [],
      "source": [
        "cnn_128.compile(optimizer=Adam(learning_rate=LR, weight_decay=WEIGHT_DECAY), loss='binary_crossentropy')\n",
        "train(cnn_128, X_train_128, Y_train_128, n_epochs=N_EPOCHS, batch_size=BATCH_SIZE, model_path=cnn_128_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--iB3U3GeX8K"
      },
      "outputs": [],
      "source": [
        "cnn_128.load_weights(cnn_64_path)\n",
        "test_metrics = evaluate(cnn_64, X_test_128, Y_test_128)\n",
        "print(f'test_acc: {test_metrics[0]}; test_f1: {test_metrics[1]}; test_auc: {test_metrics[2]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-OdeNaugo_6"
      },
      "source": [
        "## VGG-16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u48faZoQgxpX"
      },
      "outputs": [],
      "source": [
        "VGG16, preprocess_input = Classifiers.get('vgg16')\n",
        "vgg16_128 = VGG16(input_shape=(image_size_128, image_size_128, 3), weights='imagenet', include_top=False)\n",
        "# for layer in vgg16_128.layers:\n",
        "#     layer.trainable = False\n",
        "new_input = Input(shape=(image_size_128, image_size_128, 1))\n",
        "x = Conv2D(filters=3, kernel_size=(3, 3), padding=\"same\", activation=None)(new_input)\n",
        "x = vgg16_128(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "prediction = Dense(n_classes, activation='sigmoid')(x)\n",
        "vgg16_128 = Model(inputs=new_input, outputs=prediction)\n",
        "vgg16_128.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysYqtSJTgxpZ"
      },
      "outputs": [],
      "source": [
        "vgg16_128_path = f'{model_folder}/vgg16_128.weights.h5'\n",
        "vgg16_128.compile(optimizer=Adam(learning_rate=LR, weight_decay=WEIGHT_DECAY), loss='binary_crossentropy')\n",
        "train(vgg16_64, X_train_128, Y_train_128, n_epochs=N_EPOCHS, batch_size=BATCH_SIZE, model_path=vgg16_128_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJog-xBogxpa"
      },
      "outputs": [],
      "source": [
        "vgg16_128.load_weights(vgg16_128_path)\n",
        "test_metrics = evaluate(vgg16_64, X_test_128, Y_test_128)\n",
        "print(f'test_acc: {test_metrics[0]}; test_f1: {test_metrics[1]}; test_auc: {test_metrics[2]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rup0-MLehYtQ"
      },
      "source": [
        "## VGG-19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CB0_kOejhaWL"
      },
      "outputs": [],
      "source": [
        "VGG19, preprocess_input = Classifiers.get('vgg19')\n",
        "vgg19_128 = VGG19(input_shape=(image_size_128, image_size_128, 3), weights='imagenet', include_top=False)\n",
        "# for layer in vgg19_224.layers:\n",
        "#     layer.trainable = False\n",
        "\n",
        "new_input = Input(shape=(image_size_128, image_size_128, 1))\n",
        "x = Conv2D(filters=3, kernel_size=(3, 3), padding=\"same\", activation=None)(new_input)\n",
        "x = vgg19_128(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "prediction = Dense(n_classes, activation='sigmoid')(x)\n",
        "vgg19_128 = Model(inputs=new_input, outputs=prediction)\n",
        "vgg19_128.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AavtjXYFhaWM"
      },
      "outputs": [],
      "source": [
        "vgg19_128_path = f'{model_folder}/vgg19_128.weights.h5'\n",
        "vgg19_128.compile(optimizer=Adam(learning_rate=LR, weight_decay=WEIGHT_DECAY), loss=B'binary_crossentropy')\n",
        "train(vgg19_64, X_train_128, Y_train_128, n_epochs=N_EPOCHS, model_path=vgg19_128_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyLvtCAbhaWN"
      },
      "outputs": [],
      "source": [
        "vgg19_128.load_weights(vgg19_64_path)\n",
        "test_metrics = evaluate(vgg19_64, X_test_64, Y_test_64)\n",
        "print(f'test_acc: {test_metrics[0]}; test_f1: {test_metrics[1]}; test_auc: {test_metrics[2]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2ojix4ehvDu"
      },
      "source": [
        "## ResNet-18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3pCIgiVh3SM"
      },
      "outputs": [],
      "source": [
        "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
        "resnet18_128 = ResNet18(input_shape=(image_size_128, image_size_128, 3), weights='imagenet', include_top=False)\n",
        "# for layer in resnet18_64.layers:\n",
        "#     layer.trainable = False\n",
        "new_input = Input(shape=(image_size_128, image_size_128, 1))\n",
        "x = Conv2D(filters=3, kernel_size=(3, 3), padding=\"same\", activation='relu')(new_input)\n",
        "x = resnet18_128(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "prediction = Dense(n_classes, activation='sigmoid')(x)\n",
        "resnet18_128 = Model(inputs=new_input, outputs=prediction)\n",
        "resnet18_128.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaNPr9-Rh3SO"
      },
      "outputs": [],
      "source": [
        "resnet18_128_path = f'{model_folder}/resnet18_128.weights.h5'\n",
        "resnet18_128.compile(optimizer=Adam(learning_rate=LR, weight_decay=WEIGHT_DECAY), loss='binary_crossentropy')\n",
        "train(resnet18_64, X_train_128, Y_train_128, n_epochs=N_EPOCHS, batch_size=BATCH_SIZE, model_path=resnet18_128_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmkcafyPh3SO"
      },
      "outputs": [],
      "source": [
        "resnet18_128.load_weights(resnet18_128_path)\n",
        "test_metrics = evaluate(resnet18_128, X_test_128, Y_test_128)\n",
        "print(f'test_acc: {test_metrics[0]}; test_f1: {test_metrics[1]}; test_auc: {test_metrics[2]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THHwD7G5iNiF"
      },
      "source": [
        "## ResNet-50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psl_kfgDiUnu"
      },
      "outputs": [],
      "source": [
        "ResNet50, preprocess_input = Classifiers.get('resnet50')\n",
        "resnet50_128 = ResNet50(input_shape=(image_size_128, image_size_128, 3), weights='imagenet', include_top=False)\n",
        "# for layer in resnet50_128.layers:\n",
        "#     layer.trainable = False\n",
        "new_input = Input(shape=(image_size_128, image_size_128, 1))\n",
        "x = Conv2D(filters=3, kernel_size=(3, 3), padding=\"same\", activation='relu')(new_input)\n",
        "x = resnet50_128(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "prediction = Dense(n_classes, activation='sigmoid')(x)\n",
        "resnet50_128 = Model(inputs=new_input, outputs=prediction)\n",
        "resnet50_128.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0gbDeJkiUnw"
      },
      "outputs": [],
      "source": [
        "resnet50_128_path = f'{model_folder}/resnet50_128.weights.h5'\n",
        "resnet50_128.compile(optimizer=Adam(learning_rate=LR, weight_decay=WEIGHT_DECAY), loss='binary_crossentropy')\n",
        "train(resnet50_128, X_train_128, Y_train_128, n_epochs=N_EPOCHS, batch_size=BATCH_SIZE, model_path=resnet50_128_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iN5uixuUiUnw"
      },
      "outputs": [],
      "source": [
        "resnet50_128.load_weights(resnet50_128_path)\n",
        "test_metrics = evaluate(resnet50_128, X_test_128, Y_test_128)\n",
        "print(f'test_acc: {test_metrics[0]}; test_f1: {test_metrics[1]}; test_auc: {test_metrics[2]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fwyoc_zqlLo5"
      },
      "source": [
        "## SHViT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBTI1TCfm2eJ"
      },
      "outputs": [],
      "source": [
        "shvit_settings = {\n",
        "        'embed_dim': [128, 224, 320],\n",
        "        'depth': [2, 4, 5],\n",
        "        'partial_dim': [32, 48, 68],\n",
        "        'types' : ['i', 's', 's']\n",
        "    }\n",
        "shvit = SHVIT(**shvit_settings)\n",
        "input = Input(shape=(image_size_128, image_size_128, 1))\n",
        "output = shvit(input)\n",
        "shvit_128 = Model(inputs=input, outputs=output)\n",
        "shvit_128.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6hxGXGjm2eL"
      },
      "outputs": [],
      "source": [
        "shvit_128_path = f'{model_folder}/shvit_128.weights.h5'\n",
        "shvit_128.compile(optimizer=Adam(learning_rate=LR, weight_decay=WEIGHT_DECAY), loss='binary_crossentropy')\n",
        "train(shvit_128, X_train_128, Y_train_128, n_epochs=1, batch_size=BATCH_SIZE, model_path=shvit_128_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xASSn5Cm2eL"
      },
      "outputs": [],
      "source": [
        "shvit_128.load_weights(shvit_128_path)\n",
        "test_metrics = evaluate(shvit_128, X_test_128, Y_test_128)\n",
        "print(f'test_acc: {test_metrics[0]}; test_f1: {test_metrics[1]}; test_auc: {test_metrics[2]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Epj3a329m313"
      },
      "source": [
        "# 224x224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xadBc6gcnIR2"
      },
      "outputs": [],
      "source": [
        "image_size_224 = 224\n",
        "data_224 = load_data(dataset_folder, data_flag, size_flag=image_size_224)\n",
        "X_train_224, Y_train_224, X_test_224, Y_test_224 = np.expand_dims(data_224[0], axis=-1)/255, data_224[1], np.expand_dims(data_224[4], axis=-1), data_224[5]\n",
        "X_train_224, X_test_224 = np.expand_dims(X_train_224, axis=-1)/255, np.expand_dims(X_test_224, axis=-1)/255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSrIJy0fnZRH"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGKuP06_oOt1"
      },
      "outputs": [],
      "source": [
        "cnn_224 = CNN(image_size_224, n_classes)\n",
        "cnn_224.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaYL72qboOt5"
      },
      "outputs": [],
      "source": [
        "cnn_224_path = f'{model_folder}/cnn_224.weights.h5'\n",
        "cnn_224.compile(optimizer=Adam(learning_rate=LR, weight_decay=WEIGHT_DECAY), loss='binary_crossentropy')\n",
        "train(cnn_224, X_train_224, Y_train_224, n_epochs=N_EPOCHS, batch_size=BATCH_SIZE, model_path=cnn_224_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFGZYWs6oOt5"
      },
      "outputs": [],
      "source": [
        "cnn_224.load_state_dict(torch.load(cnn_224_path, map_location=DEVICE))\n",
        "test_metrics = evaluate(cnn_224, test_loader_224, device=DEVICE)\n",
        "print(f'test_acc: {test_metrics[0]}; test_f1: {test_metrics[1]}; test_auc: {test_metrics[2]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-fDGLdGnaeh"
      },
      "source": [
        "## VGG-16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aX5XStZ5oo8m"
      },
      "outputs": [],
      "source": [
        "VGG16, preprocess_input = Classifiers.get('vgg16')\n",
        "vgg16_224 = VGG16(input_shape=(image_size_224, image_size_224, 3), weights='imagenet', include_top=False)\n",
        "# for layer in vgg16_224.layers:\n",
        "#     layer.trainable = False\n",
        "new_input = Input(shape=(image_size_224, image_size_224, 1))\n",
        "x = Conv2D(filters=3, kernel_size=(3, 3), padding=\"same\", activation=None)(new_input)\n",
        "x = vgg16_224(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "prediction = Dense(n_classes, activation='sigmoid')(x)\n",
        "vgg16_224 = Model(inputs=new_input, outputs=prediction)\n",
        "vgg16_224.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bl7a8Yyoo8n"
      },
      "outputs": [],
      "source": [
        "vgg16_224_path = f'{model_folder}/vgg16_224.weights.h5'\n",
        "vgg16_224.compile(optimizer=Adam(learning_rate=LR, weight_decay=WEIGHT_DECAY), loss='binary_crossentropy')\n",
        "train(vgg16_64, X_train_224, Y_train_224, n_epochs=N_EPOCHS, batch_size=BATCH_SIZE, model_path=vgg16_224_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2B_tHS9Ioo8p"
      },
      "outputs": [],
      "source": [
        "vgg16_224.load_weights(vgg16_224_path)\n",
        "test_metrics = evaluate(vgg16_64, X_test_224, Y_test_224)\n",
        "print(f'test_acc: {test_metrics[0]}; test_f1: {test_metrics[1]}; test_auc: {test_metrics[2]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWYPNvw-opvd"
      },
      "source": [
        "## VGG-19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4HkDnrQpDg8"
      },
      "outputs": [],
      "source": [
        "VGG19, preprocess_input = Classifiers.get('vgg19')\n",
        "vgg19_224 = VGG19(input_shape=(image_size_224, image_size_224, 3), weights='imagenet', include_top=False)\n",
        "# for layer in vgg19_224.layers:\n",
        "#     layer.trainable = False\n",
        "\n",
        "new_input = Input(shape=(image_size_224, image_size_224, 1))\n",
        "x = Conv2D(filters=3, kernel_size=(3, 3), padding=\"same\", activation=None)(new_input)\n",
        "x = vgg19_224(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "prediction = Dense(n_classes, activation='sigmoid')(x)\n",
        "vgg19_224 = Model(inputs=new_input, outputs=prediction)\n",
        "vgg19_224.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5WEnrMGpDhB"
      },
      "outputs": [],
      "source": [
        "vgg19_224_path = f'{model_folder}/vgg19_224.weights.h5'\n",
        "vgg19_224.compile(optimizer=Adam(learning_rate=LR, weight_decay=WEIGHT_DECAY), loss=B'binary_crossentropy')\n",
        "train(vgg19_64, X_train_128, Y_train_128, n_epochs=N_EPOCHS, model_path=vgg19_224_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPXmQDtQpDhB"
      },
      "outputs": [],
      "source": [
        "vgg19_128.load_weights(vgg19_64_path)\n",
        "test_metrics = evaluate(vgg19_64, X_test_64, Y_test_64)\n",
        "print(f'test_acc: {test_metrics[0]}; test_f1: {test_metrics[1]}; test_auc: {test_metrics[2]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIpDaoj2ncFQ"
      },
      "source": [
        "## ResNet-18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0w9Lb6qIpSQ4"
      },
      "outputs": [],
      "source": [
        "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
        "resnet18_224 = ResNet18(input_shape=(image_size_224, image_size_224, 3), weights='imagenet', include_top=False)\n",
        "# for layer in resnet18_64.layers:\n",
        "#     layer.trainable = False\n",
        "new_input = Input(shape=(image_size_224, image_size_224, 1))\n",
        "x = Conv2D(filters=3, kernel_size=(3, 3), padding=\"same\", activation='relu')(new_input)\n",
        "x = resnet18_224(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "prediction = Dense(n_classes, activation='sigmoid')(x)\n",
        "resnet18_224 = Model(inputs=new_input, outputs=prediction)\n",
        "resnet18_224.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdHIAzZkpSQ5"
      },
      "outputs": [],
      "source": [
        "resnet18_224_path = f'{model_folder}/resnet18_224.weights.h5'\n",
        "resnet18_224.compile(optimizer=Adam(learning_rate=LR, weight_decay=WEIGHT_DECAY), loss='binary_crossentropy')\n",
        "train(resnet18_224, X_train_224, Y_train_224, n_epochs=N_EPOCHS, batch_size=BATCH_SIZE, model_path=resnet18_224_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_RSOwlVpSQ6"
      },
      "outputs": [],
      "source": [
        "resnet18_224.load_weights(resnet18_224_path)\n",
        "test_metrics = evaluate(resnet18_128, X_test_224, Y_test_224)\n",
        "print(f'test_acc: {test_metrics[0]}; test_f1: {test_metrics[1]}; test_auc: {test_metrics[2]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ub94A2Bnd1G"
      },
      "source": [
        "## ResNet-50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZL_Pf8Pp3MV"
      },
      "outputs": [],
      "source": [
        "ResNet50, preprocess_input = Classifiers.get('resnet50')\n",
        "resnet50_224 = ResNet50(input_shape=(image_size_224, image_size_224, 3), weights='imagenet', include_top=False)\n",
        "# for layer in resnet50_224.layers:\n",
        "#     layer.trainable = False\n",
        "new_input = Input(shape=(image_size_224, image_size_224, 1))\n",
        "x = Conv2D(filters=3, kernel_size=(3, 3), padding=\"same\", activation='relu')(new_input)\n",
        "x = resnet50_224(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "prediction = Dense(n_classes, activation='sigmoid')(x)\n",
        "resnet50_224 = Model(inputs=new_input, outputs=prediction)\n",
        "resnet50_224.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUdoeHnRp3MW"
      },
      "outputs": [],
      "source": [
        "resnet50_224_path = f'{model_folder}/resnet50_224.weights.h5'\n",
        "resnet50_224.compile(optimizer=Adam(learning_rate=LR, weight_decay=WEIGHT_DECAY), loss='binary_crossentropy')\n",
        "train(resnet50_128, X_train_224, Y_train_224, n_epochs=N_EPOCHS, batch_size=BATCH_SIZE, model_path=resnet50_224_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjSoVzu_p3MX"
      },
      "outputs": [],
      "source": [
        "resnet50_224.load_weights(resnet50_224_path)\n",
        "test_metrics = evaluate(resnet50_128, X_test_224, Y_test_224)\n",
        "print(f'test_acc: {test_metrics[0]}; test_f1: {test_metrics[1]}; test_auc: {test_metrics[2]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3gkyXitn2Dj"
      },
      "source": [
        "## SHViT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpvU-VaorsyK"
      },
      "outputs": [],
      "source": [
        "shvit_settings = {\n",
        "        'embed_dim': [128, 224, 320],\n",
        "        'depth': [2, 4, 5],\n",
        "        'partial_dim': [32, 48, 68],\n",
        "        'types' : ['i', 's', 's']\n",
        "    }\n",
        "shvit = SHVIT(**shvit_settings)\n",
        "input = Input(shape=(image_size_224, image_size_224, 1))\n",
        "output = shvit(input)\n",
        "shvit_224 = Model(inputs=input, outputs=output)\n",
        "shvit_224.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "recFVNOPrsyN"
      },
      "outputs": [],
      "source": [
        "shvit_224.compile(optimizer=Adam(learning_rate=LR, weight_decay=WEIGHT_DECAY), loss='binary_crossentropy')\n",
        "train(shvit_224, X_train_224, Y_train_224, n_epochs=1, batch_size=BATCH_SIZE, model_path=shvit_224_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tY5tyCBcr0JB"
      },
      "outputs": [],
      "source": [
        "shvit_224.load_weights(shvit_224_path)\n",
        "test_metrics = evaluate(shvit_128, X_test_224, Y_test_224)\n",
        "print(f'test_acc: {test_metrics[0]}; test_f1: {test_metrics[1]}; test_auc: {test_metrics[2]}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
